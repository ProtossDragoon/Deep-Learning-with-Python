{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Segmentation Augmentation Layer With TPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPEyckLhq+oVFAJofxCl78d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProtossDragoon/Deep-Learning-with-Python/blob/main/Segmentation_Augmentation_Layer_With_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91FkBbrbsdDP"
      },
      "source": [
        "# Segmentation Augmentation Layer With TPU\n",
        "\n",
        "## Author\n",
        "\n",
        "name : Janghoo Lee <br>\n",
        "github : https://github.com/ProtossDragoon <br>\n",
        "contact : dlwkdgn1@naver.com <br>\n",
        "published date : November, 2021\n",
        "\n",
        "## ThridParty\n",
        "\n",
        "- github : https://github.com/qubvel/segmentation_models\n",
        "\n",
        "## Related Issue\n",
        "\n",
        "- issue : https://github.com/tensorflow/tensorflow/issues/53051"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jTwqlPkcSF4"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8NQEq535eIy"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os, sys\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP24LkbSpIKh"
      },
      "source": [
        "### Setup CPU/GPU/TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKftu2v8IdsJ",
        "outputId": "46509976-a269-4de6-e7f1-4108418694c4"
      },
      "source": [
        "if 'COLAB_TPU_ADDR' in os.environ: # Check TPU\n",
        "    assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU.'\n",
        "    tf_master = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "    TPU_ADDRESS = tf_master\n",
        "            \n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "    tf.config.experimental_connect_to_cluster(resolver) # initialize the colab tpu\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver) # https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/keras_mnist_tpu.ipynb?hl=ko&authuser=2#scrollTo=Hd5zB1G7Y9-7\n",
        "\n",
        "    TRAINING_PARALLEL_STRATEGY = tf.distribute.TPUStrategy(resolver) # Choose distribution strategy for parallel processing.\n",
        "    tpus = tf.config.list_logical_devices('TPU')\n",
        "    print(f'total {len(tpus)} of TPU devices: {tpus}')\n",
        "\n",
        "    USE_TPU = True\n",
        "    USE_GPU = False\n",
        "else: \n",
        "    USE_TPU = False\n",
        "    print('TPU Not found')\n",
        "    TRAINING_PARALLEL_STRATEGY = None\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if not device_name:\n",
        "        USE_GPU = False\n",
        "        print('GPU device not found.')\n",
        "    else:\n",
        "        USE_GPU = True\n",
        "        !nvidia-smi -L\n",
        "        gpus = tf.config.list_logical_devices('GPU')\n",
        "        print(f'total {len(gpus)} GPU devices: {gpus}')\n",
        "\n",
        "if USE_TPU:\n",
        "    CURRENT_DEVICE = 'tpu'\n",
        "elif USE_GPU:\n",
        "    CURRENT_DEVICE = 'gpu'\n",
        "else:\n",
        "    CURRENT_DEVICE = 'cpu'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.25.231.146:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.25.231.146:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.25.231.146:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.25.231.146:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8 of TPU devices: [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cifikJD1OJiM"
      },
      "source": [
        "## Create dummy data for segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69KniFI7PIVD"
      },
      "source": [
        "def make_dummy_data(\n",
        "    image_input_hw:tuple, \n",
        "    mask_input_hw:tuple,\n",
        "    class_n:int,\n",
        "    data_n:int=50,\n",
        "):\n",
        "    _default_channel_n = 3\n",
        "    image_input_shape = [data_n] + list(image_input_hw) + [_default_channel_n]\n",
        "    mask_input_shape = [data_n] + list(mask_input_hw) + [class_n]\n",
        "    return np.zeros(image_input_shape), np.zeros(mask_input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ErLbxcoFXCj",
        "outputId": "2ca3776c-8e45-45ad-fa42-b1e7e829fde3"
      },
      "source": [
        "image_input_hw = (224, 224)\n",
        "mask_input_hw = (224, 224)\n",
        "class_n = 10\n",
        "\n",
        "im, ma = make_dummy_data(image_input_hw, mask_input_hw, class_n=class_n)\n",
        "print(f'image : {im.shape}')\n",
        "print(f'mask : {ma.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image : (50, 224, 224, 3)\n",
            "mask : (50, 224, 224, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu6DTQXxXa6x"
      },
      "source": [
        "# tf.data.Dataset 객체 생성을 도와주는 함수\n",
        "def make_tensorflow_dataset(\n",
        "    batched_images,\n",
        "    batched_masks,\n",
        "    batch_size:int=10,\n",
        "):\n",
        "    \"\"\"Helper function to create tf.data.Dataset object\n",
        "    \"\"\"\n",
        "    def assert_valid_shape(\n",
        "        batched_images_shape,\n",
        "        batched_masks_shape,\n",
        "    ):\n",
        "        \"\"\"Shape assertion function\n",
        "        \"\"\"\n",
        "        assert len(batched_images_shape) == 4\n",
        "        assert len(batched_masks_shape) == 4\n",
        "        assert batched_images_shape[0] == batched_masks_shape[0]\n",
        "        assert batched_images_shape[1] == batched_masks_shape[1]\n",
        "        assert batched_images_shape[2] == batched_masks_shape[2]\n",
        "\n",
        "    assert_valid_shape(batched_images.shape, batched_masks.shape)\n",
        "\n",
        "    images_tf = tf.data.Dataset.from_tensor_slices(batched_images)\n",
        "    masks_tf = tf.data.Dataset.from_tensor_slices(batched_masks)\n",
        "    dataset = tf.data.Dataset.zip((images_tf, masks_tf))\n",
        "    dataset = dataset.shuffle(buffer_size=100).batch(batch_size, drop_remainder=True)\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2bm5UpGZOUQ",
        "outputId": "0efc2dc2-5d71-4aa4-ca14-3d2c624dc0a5"
      },
      "source": [
        "# tf.data.Dataset 객체 생성. \n",
        "# TensorFlow 의 모델에 입력할 때에는 이 객체를 주로 사용.\n",
        "tf_dataset = make_tensorflow_dataset(im, ma)\n",
        "\n",
        "# 데이터 1개만 꺼내보기\n",
        "def get_a_batch(tf_dataset):\n",
        "    debug_iter = iter(tf_dataset)\n",
        "    _im, _ma = batch = next(debug_iter)\n",
        "    return batch\n",
        "\n",
        "im, ma = get_a_batch(tf_dataset)\n",
        "print(f'{type(im)} typed image tensor: {im.shape}')\n",
        "print(f'{type(ma)} typed mask tensor: {ma.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'> typed image tensor: (10, 224, 224, 3)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'> typed mask tensor: (10, 224, 224, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfIzhvWsQCsS"
      },
      "source": [
        "## Create model for segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2hQYhEdO42S",
        "outputId": "5f7cadd2-b935-4857-fcc8-ef1c6fe8592f"
      },
      "source": [
        "GIT_REPO_THIRDPARTY_NAME = 'segmentation_models'\n",
        "!git clone https://github.com/qubvel/{GIT_REPO_THIRDPARTY_NAME}.git -q\n",
        "!pip install {GIT_REPO_THIRDPARTY_NAME} -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'segmentation_models' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh724YKBQHwS"
      },
      "source": [
        "def auto_tpu(device='cpu'):\n",
        "    \"\"\"Automatically open context manager\n",
        "    If your colab environment is on 'tpu'\n",
        "    \"\"\"\n",
        "    def decorator(fn):\n",
        "        def wrapper(*args, **kwargs):\n",
        "            s = time.time()\n",
        "            if device == 'tpu':\n",
        "                with TRAINING_PARALLEL_STRATEGY.scope():\n",
        "                    ret = fn(*args, **kwargs)\n",
        "            else:\n",
        "                ret = fn(*args, **kwargs)\n",
        "            e = time.time()\n",
        "            print(f'device: {repr(device)}, time elapse: {e-s:.3} second(s)')\n",
        "            return ret\n",
        "        return wrapper\n",
        "    return decorator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R6XZp43PvWC",
        "outputId": "a3c4bab8-fc7f-4280-9e71-7f1fc90a9150"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "import segmentation_models as sm\n",
        "sm.set_framework('tf.keras')\n",
        "\n",
        "@auto_tpu(device=CURRENT_DEVICE)\n",
        "def create_segmentation_model(class_n):\n",
        "    model = sm.Unet(\n",
        "        'vgg16',\n",
        "        classes=class_n, \n",
        "        activation='softmax',\n",
        "        encoder_weights=None,\n",
        "        encoder_freeze=False,\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = create_segmentation_model(class_n)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: 'tpu', time elapse: 2.28 second(s)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
            "                                 3)]                                                              \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, None, None,   1792        ['input_1[0][0]']                \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, None, None,   36928       ['block1_conv1[0][0]']           \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, None, None,   0           ['block1_conv2[0][0]']           \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, None, None,   73856       ['block1_pool[0][0]']            \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, None, None,   147584      ['block2_conv1[0][0]']           \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, None, None,   0           ['block2_conv2[0][0]']           \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, None, None,   295168      ['block2_pool[0][0]']            \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, None, None,   590080      ['block3_conv1[0][0]']           \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, None, None,   590080      ['block3_conv2[0][0]']           \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, None, None,   0           ['block3_conv3[0][0]']           \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, None, None,   1180160     ['block3_pool[0][0]']            \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, None, None,   2359808     ['block4_conv1[0][0]']           \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, None, None,   2359808     ['block4_conv2[0][0]']           \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, None, None,   0           ['block4_conv3[0][0]']           \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, None, None,   2359808     ['block4_pool[0][0]']            \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, None, None,   2359808     ['block5_conv1[0][0]']           \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, None, None,   2359808     ['block5_conv2[0][0]']           \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " block5_pool (MaxPooling2D)     (None, None, None,   0           ['block5_conv3[0][0]']           \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " center_block1_conv (Conv2D)    (None, None, None,   2359296     ['block5_pool[0][0]']            \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " center_block1_bn (BatchNormali  (None, None, None,   2048       ['center_block1_conv[0][0]']     \n",
            " zation)                        512)                                                              \n",
            "                                                                                                  \n",
            " center_block1_relu (Activation  (None, None, None,   0          ['center_block1_bn[0][0]']       \n",
            " )                              512)                                                              \n",
            "                                                                                                  \n",
            " center_block2_conv (Conv2D)    (None, None, None,   2359296     ['center_block1_relu[0][0]']     \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " center_block2_bn (BatchNormali  (None, None, None,   2048       ['center_block2_conv[0][0]']     \n",
            " zation)                        512)                                                              \n",
            "                                                                                                  \n",
            " center_block2_relu (Activation  (None, None, None,   0          ['center_block2_bn[0][0]']       \n",
            " )                              512)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage0_upsampling (UpS  (None, None, None,   0          ['center_block2_relu[0][0]']     \n",
            " ampling2D)                     512)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage0_concat (Concate  (None, None, None,   0          ['decoder_stage0_upsampling[0][0]\n",
            " nate)                          1024)                            ',                               \n",
            "                                                                  'block5_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " decoder_stage0a_conv (Conv2D)  (None, None, None,   2359296     ['decoder_stage0_concat[0][0]']  \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage0a_bn (BatchNorma  (None, None, None,   1024       ['decoder_stage0a_conv[0][0]']   \n",
            " lization)                      256)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage0a_relu (Activati  (None, None, None,   0          ['decoder_stage0a_bn[0][0]']     \n",
            " on)                            256)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage0b_conv (Conv2D)  (None, None, None,   589824      ['decoder_stage0a_relu[0][0]']   \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage0b_bn (BatchNorma  (None, None, None,   1024       ['decoder_stage0b_conv[0][0]']   \n",
            " lization)                      256)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage0b_relu (Activati  (None, None, None,   0          ['decoder_stage0b_bn[0][0]']     \n",
            " on)                            256)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage1_upsampling (UpS  (None, None, None,   0          ['decoder_stage0b_relu[0][0]']   \n",
            " ampling2D)                     256)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage1_concat (Concate  (None, None, None,   0          ['decoder_stage1_upsampling[0][0]\n",
            " nate)                          768)                             ',                               \n",
            "                                                                  'block4_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " decoder_stage1a_conv (Conv2D)  (None, None, None,   884736      ['decoder_stage1_concat[0][0]']  \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage1a_bn (BatchNorma  (None, None, None,   512        ['decoder_stage1a_conv[0][0]']   \n",
            " lization)                      128)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage1a_relu (Activati  (None, None, None,   0          ['decoder_stage1a_bn[0][0]']     \n",
            " on)                            128)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage1b_conv (Conv2D)  (None, None, None,   147456      ['decoder_stage1a_relu[0][0]']   \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage1b_bn (BatchNorma  (None, None, None,   512        ['decoder_stage1b_conv[0][0]']   \n",
            " lization)                      128)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage1b_relu (Activati  (None, None, None,   0          ['decoder_stage1b_bn[0][0]']     \n",
            " on)                            128)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage2_upsampling (UpS  (None, None, None,   0          ['decoder_stage1b_relu[0][0]']   \n",
            " ampling2D)                     128)                                                              \n",
            "                                                                                                  \n",
            " decoder_stage2_concat (Concate  (None, None, None,   0          ['decoder_stage2_upsampling[0][0]\n",
            " nate)                          384)                             ',                               \n",
            "                                                                  'block3_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " decoder_stage2a_conv (Conv2D)  (None, None, None,   221184      ['decoder_stage2_concat[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage2a_bn (BatchNorma  (None, None, None,   256        ['decoder_stage2a_conv[0][0]']   \n",
            " lization)                      64)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage2a_relu (Activati  (None, None, None,   0          ['decoder_stage2a_bn[0][0]']     \n",
            " on)                            64)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage2b_conv (Conv2D)  (None, None, None,   36864       ['decoder_stage2a_relu[0][0]']   \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage2b_bn (BatchNorma  (None, None, None,   256        ['decoder_stage2b_conv[0][0]']   \n",
            " lization)                      64)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage2b_relu (Activati  (None, None, None,   0          ['decoder_stage2b_bn[0][0]']     \n",
            " on)                            64)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage3_upsampling (UpS  (None, None, None,   0          ['decoder_stage2b_relu[0][0]']   \n",
            " ampling2D)                     64)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage3_concat (Concate  (None, None, None,   0          ['decoder_stage3_upsampling[0][0]\n",
            " nate)                          192)                             ',                               \n",
            "                                                                  'block2_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " decoder_stage3a_conv (Conv2D)  (None, None, None,   55296       ['decoder_stage3_concat[0][0]']  \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage3a_bn (BatchNorma  (None, None, None,   128        ['decoder_stage3a_conv[0][0]']   \n",
            " lization)                      32)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage3a_relu (Activati  (None, None, None,   0          ['decoder_stage3a_bn[0][0]']     \n",
            " on)                            32)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage3b_conv (Conv2D)  (None, None, None,   9216        ['decoder_stage3a_relu[0][0]']   \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage3b_bn (BatchNorma  (None, None, None,   128        ['decoder_stage3b_conv[0][0]']   \n",
            " lization)                      32)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage3b_relu (Activati  (None, None, None,   0          ['decoder_stage3b_bn[0][0]']     \n",
            " on)                            32)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage4_upsampling (UpS  (None, None, None,   0          ['decoder_stage3b_relu[0][0]']   \n",
            " ampling2D)                     32)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage4a_conv (Conv2D)  (None, None, None,   4608        ['decoder_stage4_upsampling[0][0]\n",
            "                                16)                              ']                               \n",
            "                                                                                                  \n",
            " decoder_stage4a_bn (BatchNorma  (None, None, None,   64         ['decoder_stage4a_conv[0][0]']   \n",
            " lization)                      16)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage4a_relu (Activati  (None, None, None,   0          ['decoder_stage4a_bn[0][0]']     \n",
            " on)                            16)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage4b_conv (Conv2D)  (None, None, None,   2304        ['decoder_stage4a_relu[0][0]']   \n",
            "                                16)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage4b_bn (BatchNorma  (None, None, None,   64         ['decoder_stage4b_conv[0][0]']   \n",
            " lization)                      16)                                                               \n",
            "                                                                                                  \n",
            " decoder_stage4b_relu (Activati  (None, None, None,   0          ['decoder_stage4b_bn[0][0]']     \n",
            " on)                            16)                                                               \n",
            "                                                                                                  \n",
            " final_conv (Conv2D)            (None, None, None,   1450        ['decoder_stage4b_relu[0][0]']   \n",
            "                                10)                                                               \n",
            "                                                                                                  \n",
            " softmax (Activation)           (None, None, None,   0           ['final_conv[0][0]']             \n",
            "                                10)                                                               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,753,578\n",
            "Trainable params: 23,749,546\n",
            "Non-trainable params: 4,032\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emOkBHu_XQV5",
        "outputId": "b14df181-bd19-4e4b-9ec2-8fd390bcf187"
      },
      "source": [
        "def get_loss(class_n):\n",
        "    if class_n == 1:\n",
        "        return sm.losses.BinaryFocalLoss()\n",
        "    else:\n",
        "        return sm.losses.CategoricalFocalLoss()\n",
        "\n",
        "def get_metrics():\n",
        "    return sm.metrics.IOUScore(threshold=0.5)\n",
        "\n",
        "@auto_tpu(device=CURRENT_DEVICE)\n",
        "def run(model):\n",
        "    model.compile('adam', get_loss(class_n), get_metrics())\n",
        "    model.fit(tf_dataset)\n",
        "\n",
        "# training start\n",
        "run(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 34s 146ms/step - loss: nan - iou_score: 1.0000\n",
            "device: 'tpu', time elapse: 36.1 second(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDRVpX9YiZf6"
      },
      "source": [
        "- 지금까지는 문제가 없었다. 일반적인 TPU 동작 예제와 같다.\n",
        "- 그런데 이제 모델의 앞단에 augmentation 파이프라인을 붙이려고 하면서 문제가 생긴다.\n",
        "- Classification model 이면 별 문제가 되지 않지만, 우리는 image 와 label(mask) 모두에 augmentation 을 적용해 주어야 하기 때문이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15UhlVYdcd3Z"
      },
      "source": [
        "## Create model for augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUHDS0V-cg41"
      },
      "source": [
        "### Functional & Sequential API for segmentation task augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34j6jq2UbEjV",
        "outputId": "79a0205a-a096-4fec-a1d7-0cc3fdea929b"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "@auto_tpu(device=CURRENT_DEVICE)\n",
        "def create_augmentation_model(\n",
        "    image_input_hw, \n",
        "    mask_input_hw, \n",
        "    class_n:int\n",
        "):\n",
        "    _default_channel_n = 3\n",
        "\n",
        "    # runtime augmentation pipeline\n",
        "    seq = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "            tf.keras.layers.RandomRotation(0.02),\n",
        "        ],\n",
        "        name='sequential_augmentation_layers'\n",
        "    )\n",
        "\n",
        "    image_input_shape = list(image_input_hw) + [_default_channel_n]\n",
        "    mask_input_shape = list(image_input_hw) + [class_n]\n",
        "    x_im = tf.keras.Input(shape=image_input_shape)\n",
        "    x_ma = tf.keras.Input(shape=mask_input_shape)\n",
        "    return tf.keras.Model(\n",
        "        inputs=[x_im, x_ma], \n",
        "        outputs=[seq(x_im), seq(x_ma)],\n",
        "        name='sequential_augmentation_model'\n",
        "        )\n",
        "\n",
        "aug_model = create_augmentation_model(\n",
        "    image_input_hw,\n",
        "    mask_input_hw,\n",
        "    class_n\n",
        ")\n",
        "aug_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: 'tpu', time elapse: 0.664 second(s)\n",
            "Model: \"sequential_augmentation_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 224, 224, 1  0           []                               \n",
            "                                0)]                                                               \n",
            "                                                                                                  \n",
            " sequential_augmentation_layers  (None, 224, 224, No  0          ['input_1[0][0]',                \n",
            "  (Sequential)                  ne)                               'input_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1ClJQagh6av",
        "outputId": "7404cafc-533c-4935-a7f6-bd94870c343a"
      },
      "source": [
        "im, ma = aug_model(get_a_batch(tf_dataset))\n",
        "print(f'{type(im)} typed image tensor: {im.shape}')\n",
        "print(f'{type(ma)} typed mask tensor: {ma.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'> typed image tensor: (10, 224, 224, 3)\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'> typed mask tensor: (10, 224, 224, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEduWtDhjCwy"
      },
      "source": [
        "- 우리의 segmentation model 은 model.fit(tf_dataset) 로 훈련한다.\n",
        "- 이 model.fit(tf_dataset) 을 그대로 두고 사용하기 위해서는 도대체 어떻게 해야할까?\n",
        "- tf_datset 은 (image, mask) tuple 로 이루어져 있다.\n",
        "- model.fit(x=image, y=mask) 로 언패킹되어 들어가는 셈이다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvs_zHEKjChM"
      },
      "source": [
        "class AugConcatedSegModel(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        inputs=None,\n",
        "        outputs=None,\n",
        "        augmentation_model=None, \n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(inputs=inputs, outputs=outputs, **kwargs)\n",
        "        self.augmentation_model = augmentation_model\n",
        "\n",
        "    def train_step(self, data):\n",
        "        im, ma = data\n",
        "        im, ma = self.augmentation_model((im, ma))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            ma_pred = self(im, training=True)  # Forward pass\n",
        "            # Compute the loss value\n",
        "            # (the loss function is configured in `compile()`)\n",
        "            loss = self.compiled_loss(ma, ma_pred, regularization_losses=self.losses)\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        # Update metrics (includes the metric that tracks the loss)\n",
        "        self.compiled_metrics.update_state(ma, ma_pred)\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIR5GVutflat",
        "outputId": "ad7c040d-6d88-4962-f28f-2206a4f50136"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "def new_concatenated_model(\n",
        "    image_input_hw,\n",
        "    mask_input_hw,\n",
        "    class_n\n",
        "):\n",
        "    seg_model = create_segmentation_model(class_n)\n",
        "    aug_model = create_augmentation_model(\n",
        "        image_input_hw, mask_input_hw, class_n)\n",
        "    \n",
        "    _default_channel_n = 3\n",
        "    image_input_shape = list(image_input_hw) + [_default_channel_n]\n",
        "\n",
        "    @auto_tpu(device=CURRENT_DEVICE)\n",
        "    def create():\n",
        "        im = seg_model.input\n",
        "        model = AugConcatedSegModel(\n",
        "            inputs=im,\n",
        "            outputs=seg_model(im),\n",
        "            augmentation_model=aug_model,\n",
        "            name='seg_model_train_with_aug'\n",
        "        )\n",
        "        return model\n",
        "    \n",
        "    model = create()\n",
        "    return model\n",
        "\n",
        "new_seg_model = new_concatenated_model(\n",
        "    image_input_hw,\n",
        "    mask_input_hw,\n",
        "    class_n\n",
        ")\n",
        "new_seg_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: 'tpu', time elapse: 2.3 second(s)\n",
            "device: 'tpu', time elapse: 0.645 second(s)\n",
            "device: 'tpu', time elapse: 0.5 second(s)\n",
            "Model: \"seg_model_train_with_aug\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " model (Functional)          (None, None, None, 10)    23753578  \n",
            "                                                                 \n",
            " sequential_augmentation_mod  [(None, 224, 224, 3),    0         \n",
            " el (Functional)              (None, 224, 224, 10)]              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,753,578\n",
            "Trainable params: 23,749,546\n",
            "Non-trainable params: 4,032\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "aiiO8hKkoXwz",
        "outputId": "49ebf1f6-16f5-4c06-84c7-64cd024e2855"
      },
      "source": [
        "# start training\n",
        "run(new_seg_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-277-07b57a78fcc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 학습 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_seg_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-270-40c578c67687>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tpu'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTRAINING_PARALLEL_STRATEGY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-272-6957895f235b>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 학습 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1115\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 9 root error(s) found.\n  (0) INVALID_ARGUMENT: {{function_node __inference_train_function_692915}} Input 0 to node `sequential_augmentation_model/sequential_augmentation_layers/random_flip/stateless_random_flip_left_right/stateless_random_uniform/StatelessRandomUniformV2` with op StatelessRandomUniformV2 must be a compile-time constant.\n\nXLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.\n\n\t [[{{node sequential_augmentation_model/sequential_augmentation_layers/random_flip/stateless_random_flip_left_right/stateless_random_uniform/StatelessRandomUniformV2}}]]\n\t [[TPUReplicate/_compile/_1646634736830564460/_4]]\n  (1) INVALID_ARGUMENT: {{function_node __inference_train_function_692915}} Input 0 to node `sequential_augmentation_model/sequential_augmentation_layers/random_flip/stateless_random_flip_left_right/stateless_random_uniform/StatelessRandomUniformV2` with op StatelessRandomUniformV2 must be a compile-time constant.\n\nXLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.\n\n\t [[{{node sequential_augmentation_model/sequential_augmentation_layers/random_flip/stateless_random_flip_left_right/stateless_random_uniform/StatelessRandomUniformV2}}]]\n\t [[TPUReplicate/_compile/_1646634736830564460/_4]]\n\t [[tpu_compile_succeeded_assert/_5094882425795608634/_5/_47]]\n  (2) INVALID_ARGUMENT: {{function_node __inference_train_function_692915}} Input 0 to node `sequential_augmentation_model/sequential_augmentation_layers/random_flip/stateless_random_flip_left_right/stateless_random_uniform/StatelessRandomUniformV2` with op StatelessRandomUniformV2 must be a compile-time constant.\n\nXLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.\n\n\t [[{{node sequential_augmentation_model/sequential_augmentation_layers/random_flip/stateless_random_flip_left_right/stateless_random_uniform/StatelessRandomUniformV2}}]]\n\t [[TPUReplicate/_compile/_1646634736830564460/_4]]\n\t [[tpu_compile_succeeded_assert/_5094882425795608634/_5/_159]]\n  (3) INVALID_ARGUMENT: {{function_node __inference_train_function_692915}} Input 0 to node `sequential_augmentation_model/sequential_a ... [truncated]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK9PTDsKpLK3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "outputId": "dca50409-43f2-468f-b878-9a549c2778bb"
      },
      "source": [
        "# start training\n",
        "tf.config.set_soft_device_placement(True)\n",
        "run(new_seg_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-278-8ff9c68a21c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 학습 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_soft_device_placement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_seg_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-270-40c578c67687>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tpu'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTRAINING_PARALLEL_STRATEGY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-272-6957895f235b>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 학습 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1115\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 9 root error(s) found.\n  (0) INVALID_ARGUMENT: {{function_node __inference_train_function_705179}} Input 0 to node `sequential_augmentation_model/sequential_augmentation_layers/random_flip/stateless_random_flip_left_right/stateless_random_uniform/StatelessRandomUniformV2` with op StatelessRandomUniformV2 must be a compile-time constant.\n\nXLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.\n\n\t [[{{node sequential_augmentation_model/sequential_augmentation_layers/random_flip/stateless_random_flip_left_right/stateless_random_uniform/StatelessRandomUniformV2}}]]\n\t [[TPUReplicate/_compile/_6928292766130233489/_4]]\n  (1) INVALID_ARGUMENT: {{function_node __inference_train_function_705179}} Input 0 to node `sequential_augmentation_model/sequential_augmentation_layers/random_flip/stateless_random_flip_left_right/stateless_random_uniform/StatelessRandomUniformV2` with op StatelessRandomUniformV2 must be a compile-time constant.\n\nXLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.\n\n\t [[{{node sequential_augmentation_model/sequential_augmentation_layers/random_flip/stateless_random_flip_left_right/stateless_random_uniform/StatelessRandomUniformV2}}]]\n\t [[TPUReplicate/_compile/_6928292766130233489/_4]]\n\t [[tpu_compile_succeeded_assert/_14898046470848909582/_5/_79]]\n  (2) INVALID_ARGUMENT: {{function_node __inference_train_function_705179}} Input 0 to node `sequential_augmentation_model/sequential_augmentation_layers/random_flip/stateless_random_flip_left_right/stateless_random_uniform/StatelessRandomUniformV2` with op StatelessRandomUniformV2 must be a compile-time constant.\n\nXLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.\n\n\t [[{{node sequential_augmentation_model/sequential_augmentation_layers/random_flip/stateless_random_flip_left_right/stateless_random_uniform/StatelessRandomUniformV2}}]]\n\t [[TPUReplicate/_compile/_6928292766130233489/_4]]\n\t [[tpu_compile_succeeded_assert/_14898046470848909582/_5/_47]]\n  (3) INVALID_ARGUMENT: {{function_node __inference_train_function_705179}} Input 0 to node `sequential_augmentation_model/sequential_ ... [truncated]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBEr1gZRcxGy"
      },
      "source": [
        "\n",
        "\n",
        "- 하지만 위와 같은 형태로 돌리게 된다면, image 는 좌우반전을 시켰지만, mask 는 좌우반전을 시키지 않는 상황이 나타나게 된다. \n",
        "- 따라서, subclassing api 를 통해 augmentation 을 위한 모델을 만들고 상태를 제대로 관리해줄 수 있도록 해야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcmrIsjHdD3k"
      },
      "source": [
        "## Debug area"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OzcbPfecdje"
      },
      "source": [
        "#FIXME : 실험중. 이게 진짜 TPU 잘못인가..? Random 때문인가?\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "@auto_tpu(device=CURRENT_DEVICE)\n",
        "def create_augmentation_model(\n",
        "    image_input_hw, \n",
        "    mask_input_hw, \n",
        "    class_n:int\n",
        "):\n",
        "    _default_channel_n = 3\n",
        "\n",
        "    # 내가 추가하고 싶은 runtime augmentation pipeline\n",
        "    im_seq = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Conv2D(_default_channel_n, (3,3), padding='same'),\n",
        "            tf.keras.layers.Conv2D(_default_channel_n, (3,3), padding='same'),\n",
        "        ],\n",
        "        name='sequential_image_augmentation_layers_debug'\n",
        "    )\n",
        "    ma_seq = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Conv2D(class_n, (3,3), padding='same'),\n",
        "            tf.keras.layers.Conv2D(class_n, (3,3), padding='same'),\n",
        "        ],\n",
        "        name='sequential_mask_augmentation_layers_debug'\n",
        "    )\n",
        "\n",
        "    image_input_shape = list(image_input_hw) + [_default_channel_n]\n",
        "    mask_input_shape = list(image_input_hw) + [class_n]\n",
        "    x_im = tf.keras.Input(shape=image_input_shape)\n",
        "    x_ma = tf.keras.Input(shape=mask_input_shape)\n",
        "    return tf.keras.Model(\n",
        "        inputs=[x_im, x_ma], \n",
        "        outputs=[im_seq(x_im), ma_seq(x_ma)],\n",
        "        name='sequential_augmentation_model_debug'\n",
        "        )\n",
        "\n",
        "aug_model = create_augmentation_model(\n",
        "    image_input_hw,\n",
        "    mask_input_hw,\n",
        "    class_n\n",
        ")\n",
        "aug_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQs8k2dgEy52"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "def test_time(fn, device='cpu'):\n",
        "    def model_creation():\n",
        "        backbone_model = tf.keras.applications.VGG16(\n",
        "            input_shape=(224, 224, 3),\n",
        "            include_top=False,\n",
        "            weights=None,\n",
        "        )\n",
        "        return backbone_model\n",
        "\n",
        "    if device == 'tpu':\n",
        "        with TRAINING_PARALLEL_STRATEGY.scope():\n",
        "            backbone_model = model_creation()\n",
        "    else:\n",
        "        backbone_model = model_creation()\n",
        "\n",
        "    _s = time.time()\n",
        "    fn(backbone_model, _d, device=device)\n",
        "    _e = time.time()\n",
        "    print(f'device:{repr(device)}, caching... time elapsed:{_e-_s}')\n",
        "    s = time.time()\n",
        "    fn(backbone_model, d, device=device)\n",
        "    e = time.time()\n",
        "    print(f'device:{repr(device)}, time elapsed:{e-s}')\n",
        "\n",
        "_d = np.zeros([10, 224, 224, 3], dtype=np.uint8)\n",
        "d = np.ones([10, 224, 224, 3], dtype=np.uint8)\n",
        "\n",
        "def run(model, image_data, device):\n",
        "    if device == 'tpu':\n",
        "        with TRAINING_PARALLEL_STRATEGY.scope():\n",
        "            model(image_data)\n",
        "    else:\n",
        "        model(image_data)\n",
        "\n",
        "test_time(run, device=CURRENT_DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}